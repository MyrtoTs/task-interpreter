{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd() + '/src') # Add the 'src' directory to the system path to allow imports\n",
    "from config import llm_config_35, log_config, vessel_msg\n",
    "from request_classifier import RequestClassifierAgent\n",
    "from chat import ChatAgent\n",
    "from vessel_only import VesselAgent\n",
    "\n",
    "# Configure logging as per the configuration in config.py\n",
    "logging.basicConfig(**log_config)\n",
    "\n",
    "# Initialize the Request Classifier Agent\n",
    "request_classifier = RequestClassifierAgent(llm_config=llm_config_35)\n",
    "\n",
    "# Initialize the Chat Agent\n",
    "chat_agent = ChatAgent(llm_config=llm_config_35, system_message=\"Welcome to Digital Assistant for Digital Twin Earth!\")\n",
    "\n",
    "#Initialize the Vessel Agent\n",
    "vessel_agent = VesselAgent(llm_config_35)\n",
    "\n",
    "def main():\n",
    "    messages = [{\"role\":\"assistant\",\"content\": \"I am DA4DTE. How can I help you?\"}]\n",
    "    dialog_messages = []\n",
    "    # Simulating user input\n",
    "    user_input = 'hi'\n",
    "    while user_input!='bye':\n",
    "        answer = \"\"\n",
    "        user_input = input(messages[-1][\"content\"])\n",
    "\n",
    "        # Check if the input contains an image context\n",
    "        contains_image_user = input('Contains image(yes/no)')\n",
    "        if contains_image_user == 'yes':\n",
    "            contains_image = True\n",
    "        elif contains_image_user == 'no':\n",
    "            contains_image = False\n",
    "        messages.append({\"content\":user_input,\"role\":\"user\"})\n",
    "\n",
    "        # Request Classifier Agent tries to classify the request\n",
    "        request_existence, detected_category = request_classifier.request_existence_and_classification(user_input, contains_image=contains_image)\n",
    "\n",
    "        if not request_existence or detected_category == 'None':\n",
    "            # If no specific request or category detected, activate Chat Agent\n",
    "            final_answer = chat_agent.generate_reply(messages)\n",
    "        else:\n",
    "            a = detected_category\n",
    "            #SEARCH BY METADATA -> ONLY FOR VESSELS\n",
    "            if detected_category == 'IMAGE_RETRIEVAL_BY_CAPTION':\n",
    "                is_vessel, certainty = vessel_agent.analyze_vessel_topic(user_input)\n",
    "            # If a specific request is classified, show the engine's answer with a placeholder for link\n",
    "                if not is_vessel:\n",
    "                    answer = vessel_msg \n",
    "\n",
    "            # IF VESSELS -> SEARCH BY METADATA\n",
    "            elif detected_category == 'IMAGE_RETRIEVAL_BY_METADATA':\n",
    "                is_vessel, certainty = vessel_agent.analyze_vessel_topic(user_input)\n",
    "                if is_vessel:\n",
    "                    a = 'IMAGE_RETRIEVAL_BY_CAPTION'\n",
    "            detected_category = a\n",
    "\n",
    "            if answer !=\"\":\n",
    "                final_answer=answer\n",
    "            else:\n",
    "                final_answer = f\"\"\" {detected_category} answer [Link]\"\"\"\n",
    "        messages.append({\"role\":\"assistant\",\"content\":final_answer})\n",
    "        dialog_messages.append({\"input\":user_input, \"image\":contains_image, \"answer\":final_answer})\n",
    "\n",
    "    if user_input.lower() == 'bye':\n",
    "        dialogue_dir = 'dialogues'\n",
    "        if not os.path.exists(dialogue_dir):\n",
    "            os.makedirs(dialogue_dir)\n",
    "    # List only entries in the directory that are files\n",
    "        files = [file for file in os.listdir(dialogue_dir) if os.path.isfile(os.path.join(dialogue_dir, file))]\n",
    "        file_number = len(files)+1\n",
    "        dialog_file = 'dialog_'+ str(file_number)\n",
    "\n",
    "        file_path = dialogue_dir +'/'+dialog_file\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(dialog_messages, f, indent=4)\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
